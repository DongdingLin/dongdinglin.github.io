%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 中文简历（面向大模型/NLP方向岗位）
% 编译方式：XeLaTeX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{resume}

\usepackage[left=0.75in,top=0.6in,right=0.75in,bottom=0.6in]{geometry}
\usepackage[UTF8]{ctex}
\usepackage[hidelinks]{hyperref}

\name{林东鼎 \quad Dongding Lin}
\address{电话: (+86) 137 5006 5371 \quad 邮箱: 22037064r@connect.polyu.hk}
\address{GitHub: \url{https://github.com/DongdingLin} \quad Google Scholar: \url{https://scholar.google.com/citations?user=JM4i0R8AAAAJ}}

\begin{document}

\begin{rSection}{求职意向}
\textbf{目标岗位：}大模型算法研究员 / LLM 方向研究科学家 / NLP 算法工程师（对话与推荐）\\
\textbf{研究方向：}大语言模型、多模态 LLM、LLM 推理、对话系统、会话推荐系统\\
\textbf{当前状态：}2026 年求职季，积极寻找工业界研究岗位。
\end{rSection}

\begin{rSection}{教育背景}
\textbf{香港理工大学} \hfill {\em 2022.09 -- 至今} \\
计算学系博士研究生（NLP Group）\\
\textbf{中山大学} \hfill {\em 2017.09 -- 2020.07} \\
计算机技术硕士，GPA 3.9/4.0\\
\textbf{中山大学} \hfill {\em 2013.09 -- 2017.07} \\
软件工程学士，GPA 3.8/4.0（排名 37/433）
\end{rSection}

\begin{rSection}{研究与实习经历}

\begin{rSubsection}{华为香港研究中心（HKRC）, Fermat Lab}{\em 2025.08 -- 至今}{Research Intern（大模型相关）}{}
\item 围绕无线优化与数学推理数据构建开展研究，参与大模型训练/评测数据的设计与生成。
\item 将学术场景中的推理与对话能力迁移到工业任务，关注可落地性与工程可复用性。
\end{rSubsection}

\begin{rSubsection}{香港理工大学 NLP Group}{\em 2022.12 -- 至今}{Research Assistant / PhD Research}{导师：Prof. Wenjie Li}
\item 方向聚焦\textbf{情境会话推荐（Situated Conversational Recommendation）}、\textbf{LLM 推理}与\textbf{多模态 LLM}。
\item 提出并构建 SCREEN 基准：覆盖 1.5k 场景、2 万+ 多轮对话，系统性支持情境化会话推荐研究。
\item 以第一作者/共同一作在 ACM MM、AAAI、ACL Findings 等会议发表多篇相关论文。
\end{rSubsection}

\begin{rSubsection}{香港理工大学 NLP Group}{\em 2021.07 -- 2022.12}{Research Assistant}{导师：Prof. Wenjie Li}
\item 研究目标导向会话系统与会话推荐，设计面向目标达成的规划与生成框架。
\item 相关工作发表于 KaRS@RecSys、AAAI、TNNLS、TOIS 等。
\end{rSubsection}

\begin{rSubsection}{中科院深圳先进院 SIAT}{\em 2019.04 -- 2019.10}{Research Intern}{导师：Prof. Min Yang}
\item 研究对话式机器阅读理解，提出分层式对话流转移与推理方法（HCFTR）。
\end{rSubsection}

\end{rSection}

\begin{rSection}{代表项目与成果（LLM相关）}
\textbf{SCREEN: A Benchmark for Situated Conversational Recommendation}（ACM MM 2024）\\
\textit{第一作者}；构建情境会话推荐基准，提出并评测多个子任务，为真实场景下的会话推荐研究提供标准化基础。\\

\textbf{MIDI-Tuning: Instruct once, chat consistently in multiple rounds}（ACL 2024）\\
提出多轮交互式高效调优框架，分角色建模用户与智能体，提高多轮对话一致性与稳定性。\\

\textbf{TRIP: Target-constrained Bidirectional Planning}（TOIS 2024）\\
面向目标导向对话，提出双向规划机制（look-ahead / look-back）以提升目标达成路径质量。
\end{rSection}

\begin{rSection}{代表论文（Selected）}
\textbf{Dongding Lin}, Jian Wang, Chak Tou Leong, Wenjie Li. SCREEN: A Benchmark for Situated Conversational Recommendation. \textit{ACM MM 2024}.\\
Jian Wang, \textbf{Dongding Lin}, Wenjie Li. Target-constrained Bidirectional Planning for Generation of Target-oriented Proactive Dialogue. \textit{TOIS 2024}.\\
Jian Wang, Chak Tou Leong, Jiashuo Wang, \textbf{Dongding Lin}, Wenjie Li, Xiao-Yong Wei. Instruct once, chat consistently in multiple rounds: An efficient tuning framework for dialogue. \textit{ACL 2024}.\\
Jian Wang, Yi Cheng, \textbf{Dongding Lin}, Chak Tou Leong, Wenjie Li. Target-oriented proactive dialogue systems with personalization. \textit{EMNLP 2023}.\\
\textbf{Dongding Lin*}, Jian Wang*, Wenjie Li. COLA: Improving Conversational Recommender Systems by Collaborative Augmentation. \textit{AAAI 2023}.\\
Jian Wang*, \textbf{Dongding Lin*}, Wenjie Li. Dialogue Planning via Brownian Bridge Stochastic Process for Goal-directed Proactive Dialogue. \textit{ACL Findings 2023}.
\end{rSection}

\begin{rSection}{技术能力}
\begin{tabular}{ @{} >{\bfseries}l @{
\hspace{4ex}} l }
编程语言 & Python, C/C++, Java, JavaScript, SQL, MATLAB \\
深度学习框架 & PyTorch, TensorFlow, Hugging Face, Scikit-learn \\
研究方向能力 & LLM 训练与推理、Prompt/Agent、对话系统、会话推荐、多模态理解 \\
工程与工具 & Linux, Git, LaTeX \\
语言能力 & 中文（母语）、英文（CET-4/6, IELTS 6.5）
\end{tabular}
\end{rSection}

\begin{rSection}{荣誉奖项}
2021 百度语言与智能技术竞赛，排名 \textbf{4/750} \hfill {\em 2021.06}\\
中山大学研究生奖学金（三等奖） \hfill {\em 2018--2019}\\
Kaggle 材料质量预测竞赛，排名 \textbf{4/119} \hfill {\em 2018.04--2018.07}\\
中山大学研究生奖学金（二等奖） \hfill {\em 2017--2018}\\
中山大学优秀毕业生（前 3\%） \hfill {\em 2017.06}\\
中山大学优秀毕业论文（前 3\%） \hfill {\em 2017.06}
\end{rSection}

\end{document}
